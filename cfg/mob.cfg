[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=1   #64
subdivisions=1   #8
width=416
height=416
channels=3
momentum=0.9
decay=0.0005
angle=0
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.00005
burn_in=1000
max_batches = 500200
policy=steps
steps=15000,17000
scales=.1,.1

[convolutional]
batch_normalize=1
filters=32
size=3
stride=2
pad=1
activation=leaky

#1th 3x3
[convolutional]
batch_normalize=1
filters=32
size=3
stride=1
pad=1
group=32
activation=leaky
#1th 1x1
[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=0
activation=leaky

#2th 3x3
[convolutional]
batch_normalize=1
filters=64
size=3
stride=2
pad=1
group=64
activation=leaky
#2th 1x1
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

#3th 3x3
[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
group=128
activation=leaky
#3th 1x1
[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=0
activation=leaky

#4th 3x3
[convolutional]
batch_normalize=1
filters=128
size=3
stride=2
pad=1
group=128
activation=leaky
#4th 1x1                                              
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

#5th 3x3
[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
group=256
activation=leaky
#5th 1x1
[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=0
activation=leaky

#6th 3x3
[convolutional]
batch_normalize=1
filters=256
size=3
stride=2
pad=1
group=256
activation=leaky
#6th 1x1
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

#7th 3x3
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
group=512
activation=leaky
#7th 1x1
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

#8th 3x3
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
group=512
activation=leaky
#8th 1x1
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky


#9th 3x3
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
group=512
activation=leaky
#9th 1x1
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

#10th 3x3
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
group=512
activation=leaky
#10th 1x1
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

#11th 3x3
[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
group=512
activation=leaky
#11th 1x1
[convolutional]
batch_normalize=1
filters=512
size=1
stride=1
pad=0
activation=leaky

#12th 3x3
[convolutional]
batch_normalize=1
filters=512
size=3
stride=2
pad=1
group=512
activation=leaky
#12th 1x1
[convolutional]
batch_normalize=1
filters=1024
size=1
stride=1
pad=0
activation=leaky


#13th 3x3
[convolutional]
batch_normalize=1
filters=1024
size=3
stride=1
pad=1
group=1024
activation=leaky
#13th 1x1
[convolutional]
batch_normalize=1
filters=1024
size=1
stride=1
pad=0
activation=leaky

#######

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[route]
layers=-14

[convolutional]
batch_normalize=1
size=1
stride=1
pad=1
filters=64
activation=leaky

[reorg]
stride=2

[route]
layers=-1,-4

[convolutional]
batch_normalize=1
size=3
stride=1
pad=1
filters=1024
activation=leaky

[convolutional]
size=1
stride=1
pad=1
filters=425
activation=linear


[region]
anchors =  0.57273, 0.677385, 1.87446, 2.06253, 3.33843, 5.47434, 7.88282, 3.52778, 9.77052, 9.16828
bias_match=1
classes=80
coords=4
num=5
softmax=1
jitter=.3
rescore=1

object_scale=5
noobject_scale=1
class_scale=1
coord_scale=1

absolute=1
thresh = .6
random=1
